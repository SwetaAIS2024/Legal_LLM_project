# Tender Analysis Workflow

This project implements a workflow to analyze tender documents, extract relevant information based on questions, and consolidate the findings into an Excel spreadsheet. The workflow consists of three main Python scripts:

1.  **`generate_clues.py`**: Extracts potential clues from multiple PDF tender documents based on a list of questions.
2.  **`generate_answers.py`**: Takes the extracted clues and uses a large language model (LLM) via the Ollama API to generate answers for each clue.
3.  **`update_excel.py`**: Reads the extracted clues and generated answers, and updates an existing Excel file by adding these to the rows corresponding to the original questions.

## Overview of the Scripts

### `generate_clues.py`

This script focuses on reading multiple PDF tender documents and, for each question provided in an Excel file, attempts to find relevant excerpts (clues) within the PDFs. It utilizes a local language model (specified as `glm-4-9b-chat-1m`) loaded via the `transformers` library to perform this extraction.

**Key Functionalities:**

* **PDF Loading:** Reads text content from multiple PDF files (`ops1.pdf` to `ops9.pdf`).
* **Question Extraction:** Reads a list of questions from a specified Excel file (`final_output.xlsx`), specifically from column B. It looks for cells containing a question mark (`?`).
* **Prompt Generation:** Constructs prompts for the language model by combining the base instructions, the extracted PDF content, and each question. The prompt instructs the model to identify and extract verbatim citations relevant to the question.
* **Clue Generation:** Uses the loaded language model to generate responses (the extracted clues) for each question based on the PDF content.
* **Output Storage:** Saves the generated clues to a text file (`clues.TXT`), with each question and its corresponding clues separated by newlines. A delimiter (`SPRTION`) is used to separate the responses for different questions.

**Dependencies:**

* `torch`: For tensor operations, especially if using a GPU for the language model.
* `transformers`: For loading and using the pre-trained language model (`AutoModelForCausalLM`, `AutoTokenizer`).
* `PyPDF2`: For reading text content from PDF files.
* `openpyxl`: For reading questions from the Excel file.
* `sys`: For modifying standard output encoding.
* `io`: For handling text encoding.

**Configuration:**

* `model_path`: Specifies the local path to the language model (`C:\Users\admin\glm-4-9b-chat-1m`). **Note:** You will need to adjust this path to the location of your model.
* `excel_file_path`: Specifies the path to the Excel file containing the questions (`C:\Users\admin\Desktop\tender\final_output.xlsx`). **Note:** Adjust this path accordingly.
* `output_file`: Specifies the path where the extracted clues will be saved (`c:/users/admin/desktop/tender/clues.TXT`). **Note:** Adjust this path if needed.

### `generate_answers.py`

This script takes the clues generated by `generate_clues.py` and uses the Ollama API with the `deepseek-r1:70b` model to generate comprehensive answers for each clue (which corresponds to a question).

**Key Functionalities:**

* **Clue Reading:** Reads the extracted clues from the `clues.TXT` file, splitting them based on the `SPRTION` delimiter.
* **Prompt Construction:** For each clue, it constructs a prompt that includes a base instruction, the clue itself (which is a question), and additional instructions for generating a clear and focused answer based strictly on the provided evidence.
* **Answer Generation:** Uses the `ollama.generate` function with streaming enabled to get the model's response. It processes the stream of chunks to build the complete answer. It also attempts to extract the relevant text after a potential `</think>` tag in the model's output.
* **Answer Storage:** Appends the generated answer for each clue to a text file (`combined_ans.txt`), separated by the `SPRTION` delimiter.

**Dependencies:**

* `ollama`: For interacting with the Ollama API. **Note:** Ensure you have Ollama installed and the `deepseek-r1:70b` model is available.
* `sys`: For reconfiguring standard output encoding.

**Configuration:**

* `clues_file`: Specifies the path to the file containing the extracted clues (`c:/users/admin/desktop/tender/clues.TXT`). **Note:** This should match the output file of `generate_clues.py`.
* `output_file`: Specifies the path where the generated answers will be saved (`c:/users/admin/desktop/tender/combined_ans.txt`). **Note:** Adjust this path if needed.

### `update_excel.py`

This script reads the extracted clues from `clues.TXT` and the generated answers from `combined_ans.TXT`, and then updates the original Excel file (`final_output.xlsx`) by writing the clues into column D and the corresponding answers into column C for each question found in column B. It saves the modified Excel file to a new path.

**Key Functionalities:**

* **Data Reading:** Reads the list of clues and answers from their respective text files, using `SPRTION` as the delimiter.
* **Excel Updating:** Opens the original Excel file (`final_output.xlsx`). It iterates through the rows in column B. If a cell in column B contains a question mark (`?`), it writes the next available clue into column D and the next available answer into column C of the same row.
* **Output Saving:** Saves the updated Excel data to a new file (`final_output_modified.xlsx`).

**Dependencies:**

* `openpyxl`: For reading and writing Excel files.
* `pathlib`: For path manipulation (though not strictly necessary in the provided code, it's good practice for file paths).

**Configuration:**

* `clues_file`: Specifies the path to the file containing the extracted clues (`c:/users/admin/desktop/tender/clues.TXT`). **Note:** This should match the output file of `generate_clues.py`.
* `combined_ans_file`: Specifies the path to the file containing the generated answers (`c:/users/admin/desktop/tender/combined_ans.TXT`). **Note:** This should match the output file of `generate_answers.py`.
* `excel_file_path`: Specifies the path to the original Excel file with the questions (`C:\Users\admin\Desktop\tender\final_output.xlsx`). **Note:** Adjust this path accordingly.
* `new_excel_file_path`: Specifies the path where the updated Excel file will be saved (`C:\Users\admin\Desktop\tender\final_output_modified.xlsx`). **Note:** Adjust this path if needed.

## Usage
For installation of Ollama, please refer to this link:
[Ollama] (https://github.com/ollama/ollama)

To run the tender analysis workflow, follow these steps:

1.  **Ensure Dependencies are Installed:**
    ```bash
    pip install torch transformers PyPDF2 openpyxl ollama
    ```
2.  **Download Language Models (if necessary):**
    * For `generate_clues.py`, ensure you have the `glm-4-9b-chat-1m` model downloaded and accessible at the specified `model_path`.
    * For `generate_answers.py`, ensure you have Ollama installed and the `deepseek-r1:70b` model pulled:
        ```bash
        ollama pull deepseek-r1:70b
        ```
3.  **Prepare Input Files:**
    * Place your tender PDF documents (`ops1.pdf` to `ops9.pdf`) in the directory specified in `generate_clues.py`.
    * Ensure your Excel file (`final_output.xlsx`) containing the questions in column B is in the specified directory.
4.  **Run the Scripts in Order:**
    ```bash
    python generate_clues.py
    python generate_answers.py
    python update_excel.py
    ```
5.  **Find the Output:** The updated Excel file with the extracted clues in column D and the generated answers in column C will be saved as `final_output_modified.xlsx` in the specified directory.

## Important Notes

* **File Paths:** Ensure that all file paths in the scripts are correctly configured to match the location of your files and models.
* **Language Model Availability:** The scripts rely on specific language models. Make sure these models are correctly installed and accessible.
* **Ollama Setup:** For `generate_answers.py`, ensure that the Ollama service is running.
* **Error Handling:** The provided scripts have basic error handling (e.g., ignoring encoding errors), but more robust error handling might be necessary for production use.
* **Resource Usage:** Running large language models can be computationally intensive. Ensure you have sufficient hardware resources (CPU, GPU, RAM) available.
* **Delimiter:** The `SPRTION` delimiter is used to separate clues and answers in the intermediate text files. Ensure this delimiter is not present within your data to avoid splitting issues.
* **Question Identification:** The scripts identify questions in the Excel file by the presence of a question mark (`?`) in column B. Ensure your question format adheres to this.
